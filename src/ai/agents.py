"""
Multi-Agent System
Orchestrator + Content + Tutor + Eval + Data ì—ì´ì „íŠ¸ êµ¬í˜„
"""

import os
import json
import re
from dataclasses import dataclass
from datetime import datetime
from typing import List, Optional

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False


@dataclass
class AgentMessage:
    """ì—ì´ì „íŠ¸ ê°„ ë©”ì‹œì§€ í˜•ì‹"""
    sender: str
    receiver: str
    task: str
    payload: dict
    priority: int = 1
    timestamp: datetime = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()


def _get_client():
    """Anthropic í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key or not ANTHROPIC_AVAILABLE:
        return None
    return anthropic.Anthropic(api_key=api_key)


def _call_claude(client, system: str, user: str, max_tokens: int = 1024) -> Optional[str]:
    """Claude API í˜¸ì¶œ í—¬í¼"""
    if client is None:
        return None
    try:
        response = client.messages.create(
            model="claude-sonnet-4-5-20250929",
            max_tokens=max_tokens,
            system=system,
            messages=[{"role": "user", "content": user}],
        )
        return response.content[0].text
    except Exception as e:
        print(f"[Claude API Error] {e}")
        return None


class ContentAgent:
    """ì½˜í…ì¸  ìƒì„± ì—ì´ì „íŠ¸ - ë ˆìŠ¨, ëŒ€í™”ë¬¸, ì˜ˆë¬¸ ìƒì„±"""

    def __init__(self):
        self.client = _get_client()

    def generate_lesson(self, words: List[str], level: str = "HSK1", theme: str = None) -> dict:
        """
        ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¡œ í•™ìŠµ ë ˆìŠ¨ ìƒì„±

        Args:
            words: í•œì ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
            level: HSK ë ˆë²¨
            theme: ì£¼ì œ (ì„ íƒ)

        Returns:
            {"dialogues": [...], "grammar_points": [...], "exercises": [...]}
        """
        theme_str = f"ì£¼ì œ: {theme}" if theme else "ì¼ìƒ íšŒí™”"
        prompt = f"""ë‹¤ìŒ ì¤‘êµ­ì–´ ë‹¨ì–´ë“¤ë¡œ {level} ë ˆë²¨ í•™ìŠµ ìë£Œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
ë‹¨ì–´: {', '.join(words)}
{theme_str}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "dialogues": [
    {{
      "context": "ìƒí™© ì„¤ëª…",
      "chinese": "ì¤‘êµ­ì–´ ëŒ€í™”",
      "pinyin": "ë³‘ìŒ",
      "korean": "í•œêµ­ì–´ ë²ˆì—­"
    }}
  ],
  "grammar_points": ["ë¬¸ë²• í¬ì¸íŠ¸ 1", "ë¬¸ë²• í¬ì¸íŠ¸ 2"],
  "exercises": ["ì—°ìŠµ ë¬¸ì œ 1", "ì—°ìŠµ ë¬¸ì œ 2"]
}}"""

        system = "ë‹¹ì‹ ì€ ì¤‘êµ­ì–´ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ í•™ìŠµìë¥¼ ìœ„í•œ HSK í•™ìŠµ ìë£Œë¥¼ ë§Œë“­ë‹ˆë‹¤."
        response = _call_claude(self.client, system, prompt)

        if response:
            try:
                # JSON ë¸”ë¡ ì¶”ì¶œ
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group())
            except Exception:
                pass

        # í´ë°±: ê¸°ë³¸ í…œí”Œë¦¿
        return {
            "dialogues": [
                {
                    "context": "ê¸°ë³¸ ì¸ì‚¬",
                    "chinese": "ä½ å¥½ï¼ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ",
                    "pinyin": "NÇ hÇo! NÇ jiÃ o shÃ©nme mÃ­ngzi?",
                    "korean": "ì•ˆë…•í•˜ì„¸ìš”! ì´ë¦„ì´ ë­ì˜ˆìš”?",
                }
            ],
            "grammar_points": ["å« + åå­— (ì´ë¦„ í‘œí˜„)", "æ˜¯ êµ¬ë¬¸ (AëŠ” Bì…ë‹ˆë‹¤)"],
            "exercises": ["ë¹ˆì¹¸ ì±„ìš°ê¸°: æˆ‘___å­¦ç”Ÿã€‚(æ˜¯)", "ë²ˆì—­: ì•ˆë…•í•˜ì„¸ìš” â†’ ___"],
        }

    def generate_dialogue(self, vocabulary: List[str], situation: str, num_exchanges: int = 4) -> dict:
        """
        íŠ¹ì • ìƒí™©ì— ë§ëŠ” ëŒ€í™”ë¬¸ ìƒì„±

        Args:
            vocabulary: ì‚¬ìš©í•  ë‹¨ì–´ ëª©ë¡
            situation: ìƒí™© ì„¤ëª… (í•œêµ­ì–´)
            num_exchanges: ëŒ€í™” êµí™˜ íšŸìˆ˜

        Returns:
            {"situation": str, "exchanges": [...], "grammar_notes": [...]}
        """
        prompt = f"""ë‹¤ìŒ ì¡°ê±´ìœ¼ë¡œ ì¤‘êµ­ì–´ ëŒ€í™”ë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”:
- ìƒí™©: {situation}
- ì‚¬ìš© ë‹¨ì–´: {', '.join(vocabulary)}
- ëŒ€í™” íšŸìˆ˜: {num_exchanges}ë²ˆ êµí™˜
- ë‚œì´ë„: HSK 1-2ê¸‰

JSON í˜•ì‹:
{{
  "situation": "ìƒí™© ì„¤ëª…",
  "exchanges": [
    {{"speaker": "A", "chinese": "", "pinyin": "", "korean": ""}},
    {{"speaker": "B", "chinese": "", "pinyin": "", "korean": ""}}
  ],
  "grammar_notes": ["ë¬¸ë²• ë…¸íŠ¸"]
}}"""

        system = "ë‹¹ì‹ ì€ ì¤‘êµ­ì–´ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
        response = _call_claude(self.client, system, prompt)

        if response:
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group())
            except Exception:
                pass

        return {
            "situation": situation,
            "exchanges": [
                {"speaker": "A", "chinese": "ä½ å¥½ï¼", "pinyin": "NÇ hÇo!", "korean": "ì•ˆë…•í•˜ì„¸ìš”!"},
                {"speaker": "B", "chinese": "ä½ å¥½ï¼", "pinyin": "NÇ hÇo!", "korean": "ì•ˆë…•í•˜ì„¸ìš”!"},
            ],
            "grammar_notes": [],
        }


class TutorAgent:
    """ê°œì¸ íŠœí„° ì—ì´ì „íŠ¸ - ëŒ€í™”, ë¬¸ë²• êµì •, ì„¤ëª…"""

    def __init__(self):
        self.client = _get_client()
        self.conversation_history: List[dict] = []

    def chat(self, user_message: str, user_level: str = "beginner") -> dict:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ì‘ë‹µ ìƒì„± (êµì • í¬í•¨)

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            user_level: í•™ìŠµ ìˆ˜ì¤€

        Returns:
            {
                "response": str,
                "response_pinyin": str,
                "response_translation": str,
                "corrections": [...],
                "suggestions": [...],
                "encouragement": str
            }
        """
        system = f"""ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì¤‘êµ­ì–´ íŠœí„°ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” {user_level} ìˆ˜ì¤€ì˜ í•™ìŠµìì™€ ëŒ€í™”í•©ë‹ˆë‹¤.

ì—­í• :
1. ì¤‘êµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™” (HSK 1-2ê¸‰ ìˆ˜ì¤€)
2. ë¬¸ë²• ì˜¤ë¥˜ êµì •
3. ê²©ë ¤ì™€ í”¼ë“œë°± ì œê³µ

ì‘ë‹µ í˜•ì‹ (JSON):
{{
  "response": "ì¤‘êµ­ì–´ ì‘ë‹µ",
  "response_pinyin": "ë³‘ìŒ",
  "response_translation": "í•œêµ­ì–´ ë²ˆì—­",
  "corrections": [
    {{"original": "í‹€ë¦° í‘œí˜„", "corrected": "ì˜¬ë°”ë¥¸ í‘œí˜„", "explanation": "ì„¤ëª…"}}
  ],
  "suggestions": ["ê°œì„  ì œì•ˆ"],
  "encouragement": "ê²©ë ¤ ë©”ì‹œì§€"
}}"""

        self.conversation_history.append({"role": "user", "content": user_message})

        if self.client:
            try:
                messages = self.conversation_history[-10:]  # ìµœê·¼ 10ê°œë§Œ
                response = self.client.messages.create(
                    model="claude-sonnet-4-5-20250929",
                    max_tokens=1024,
                    system=system,
                    messages=messages,
                )
                text = response.content[0].text
                json_match = re.search(r'\{.*\}', text, re.DOTALL)
                if json_match:
                    result = json.loads(json_match.group())
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": result.get("response", ""),
                    })
                    return result
            except Exception as e:
                print(f"[TutorAgent Error] {e}")

        # í´ë°± ì‘ë‹µ
        fallback = {
            "response": "å¾ˆå¥½ï¼ç»§ç»­åŠ æ²¹ï¼",
            "response_pinyin": "HÄ›n hÇo! JÃ¬xÃ¹ jiÄyÃ³u!",
            "response_translation": "ë§¤ìš° ì¢‹ì•„ìš”! ê³„ì† í™”ì´íŒ…!",
            "corrections": [],
            "suggestions": ["ë” ë§ì€ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”!"],
            "encouragement": "ì˜ í•˜ê³  ìˆì–´ìš”! ê³„ì† ì—°ìŠµí•˜ì„¸ìš”!",
        }
        self.conversation_history.append({"role": "assistant", "content": fallback["response"]})
        return fallback

    def explain_grammar(self, sentence: str) -> dict:
        """
        ë¬¸ì¥ì˜ ë¬¸ë²• ì„¤ëª… ìƒì„±

        Args:
            sentence: ë¶„ì„í•  ì¤‘êµ­ì–´ ë¬¸ì¥

        Returns:
            {"grammar_points": [...], "similar_examples": [...], "tips": [...]}
        """
        prompt = f"""ë‹¤ìŒ ì¤‘êµ­ì–´ ë¬¸ì¥ì„ í•œêµ­ì–´ í•™ìŠµìë¥¼ ìœ„í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”: {sentence}

JSON í˜•ì‹:
{{
  "sentence": "{sentence}",
  "structure": "ë¬¸ì¥ êµ¬ì¡° ì„¤ëª…",
  "grammar_points": [
    {{"point": "ë¬¸ë²• ìš”ì†Œ", "explanation": "ì„¤ëª…", "example": "ì˜ˆë¬¸"}}
  ],
  "similar_examples": ["ë¹„ìŠ·í•œ ì˜ˆë¬¸ 1", "ë¹„ìŠ·í•œ ì˜ˆë¬¸ 2"],
  "tips": ["í•™ìŠµ íŒ 1"]
}}"""

        system = "ì¤‘êµ­ì–´ ë¬¸ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        response = _call_claude(self.client, system, prompt)

        if response:
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group())
            except Exception:
                pass

        return {
            "sentence": sentence,
            "structure": "ì£¼ì–´ + ë™ì‚¬ + ëª©ì ì–´",
            "grammar_points": [],
            "similar_examples": [],
            "tips": ["ê¸°ë³¸ ë¬¸í˜•ì„ ë¨¼ì € ìµíˆì„¸ìš”"],
        }

    def reset_conversation(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.conversation_history = []


class EvalAgent:
    """í‰ê°€ ì—ì´ì „íŠ¸ - í€´ì¦ˆ ìƒì„±, ì±„ì , ì•½ì  ë¶„ì„"""

    def __init__(self):
        self.client = _get_client()

    def generate_adaptive_quiz(self, words: List[dict], recent_scores: List[float], count: int = 10) -> List[dict]:
        """
        ì ì‘í˜• í€´ì¦ˆ ìƒì„± (ì„±ì  ê¸°ë°˜ ë‚œì´ë„ ì¡°ì ˆ)

        Args:
            words: ë‹¨ì–´ ëª©ë¡ (dict with simplified, pinyin, definitions)
            recent_scores: ìµœê·¼ í€´ì¦ˆ ì ìˆ˜ ëª©ë¡
            count: ë¬¸ì œ ìˆ˜

        Returns:
            í€´ì¦ˆ ë¬¸ì œ ëª©ë¡
        """
        difficulty = self._calculate_difficulty(recent_scores)
        return self._generate_questions(words, difficulty, count)

    def _calculate_difficulty(self, scores: List[float]) -> str:
        """ì„±ì  ê¸°ë°˜ ë‚œì´ë„ ê³„ì‚°"""
        if not scores:
            return "medium"
        avg = sum(scores) / len(scores)
        if avg >= 90:
            return "hard"
        elif avg >= 70:
            return "medium"
        return "easy"

    def _generate_questions(self, words: List[dict], difficulty: str, count: int) -> List[dict]:
        """í€´ì¦ˆ ë¬¸ì œ ìƒì„±"""
        import random
        questions = []
        available = words[:count] if len(words) >= count else words

        for i, word in enumerate(available):
            q_type = random.choice(["translation", "fill_blank", "pinyin"])

            if q_type == "translation":
                # ì¤‘êµ­ì–´ â†’ í•œêµ­ì–´ ì„ íƒ
                defs = word.get("definitions", ["ëª¨ë¦„"])
                correct = defs[0] if defs else "ëª¨ë¦„"
                wrong_words = [w for w in words if w != word]
                random.shuffle(wrong_words)
                wrong_answers = [w.get("definitions", ["?"])[0] for w in wrong_words[:3]]
                options = [correct] + wrong_answers
                random.shuffle(options)

                questions.append({
                    "id": f"q_{i}",
                    "type": "translation",
                    "question": f"'{word['simplified']}' ì˜ ëœ»ì€?",
                    "options": options,
                    "answer": correct,
                    "explanation": f"{word['simplified']} ({word.get('pinyin', '')}) = {correct}",
                    "points": 10 if difficulty == "hard" else 5,
                })

            elif q_type == "fill_blank":
                defs = word.get("definitions", ["ëª¨ë¦„"])
                meaning = defs[0] if defs else "ëª¨ë¦„"
                questions.append({
                    "id": f"q_{i}",
                    "type": "fill_blank",
                    "question": f"'{meaning}'ë¥¼ ì¤‘êµ­ì–´ë¡œ?",
                    "options": [],
                    "answer": word["simplified"],
                    "explanation": f"{meaning} = {word['simplified']}",
                    "points": 10,
                })

            elif q_type == "pinyin":
                pinyin = word.get("pinyin", "")
                wrong_words = [w for w in words if w != word]
                random.shuffle(wrong_words)
                wrong_pinyins = [w.get("pinyin", "?") for w in wrong_words[:3]]
                options = [pinyin] + wrong_pinyins
                random.shuffle(options)

                questions.append({
                    "id": f"q_{i}",
                    "type": "pinyin",
                    "question": f"'{word['simplified']}' ì˜ ë³‘ìŒì€?",
                    "options": options,
                    "answer": pinyin,
                    "explanation": f"{word['simplified']} = {pinyin}",
                    "points": 5,
                })

        return questions[:count]

    def evaluate_answer(self, question: dict, user_answer: str) -> dict:
        """
        ë‹µì•ˆ í‰ê°€

        Args:
            question: í€´ì¦ˆ ë¬¸ì œ dict
            user_answer: ì‚¬ìš©ì ë‹µì•ˆ

        Returns:
            {"is_correct": bool, "score": int, "feedback": str}
        """
        correct = question.get("answer", "")
        is_correct = user_answer.strip() == correct.strip()

        return {
            "is_correct": is_correct,
            "score": question.get("points", 5) if is_correct else 0,
            "feedback": "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰" if is_correct else f"ì˜¤ë‹µ. ì •ë‹µ: {correct}",
            "explanation": question.get("explanation", ""),
        }


class DataAgent:
    """ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸ - ì§„ë„ ë¶„ì„, ì¸ì‚¬ì´íŠ¸, ì¶”ì²œ"""

    def __init__(self, progress_tracker):
        self.tracker = progress_tracker

    def analyze_progress(self, period: str = "week") -> dict:
        """
        í•™ìŠµ ì§„ë„ ë¶„ì„

        Args:
            period: "day", "week", "month", "all"

        Returns:
            {"summary": dict, "insights": [...], "recommendations": [...]}
        """
        stats = self.tracker.get_statistics()
        level_data = self.tracker.get_user_progress()

        insights = []
        recommendations = []

        # ì¸ì‚¬ì´íŠ¸ ìƒì„±
        mastered = stats.get("mastered_words", 0)
        total = stats.get("total_words_learned", 0)
        if total > 0:
            mastery_rate = mastered / total
            if mastery_rate < 0.3:
                insights.append("âš ï¸ ë§ˆìŠ¤í„°í•œ ë‹¨ì–´ ë¹„ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. ë³µìŠµì„ ëŠ˜ë ¤ë³´ì„¸ìš”!")
                recommendations.append("ë§¤ì¼ 5ë¶„ ë³µìŠµ ì„¸ì…˜ ì¶”ê°€")
            elif mastery_rate > 0.7:
                insights.append("âœ¨ ë§ˆìŠ¤í„° ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤! ìƒˆ ë‹¨ì–´ì— ë„ì „í•´ë³´ì„¸ìš”.")
                recommendations.append("ë‹¤ìŒ ë ˆìŠ¨ìœ¼ë¡œ ì§„í–‰í•˜ì„¸ìš”")

        streak = level_data.get("current_streak", 0)
        if streak == 0:
            recommendations.append("ì˜¤ëŠ˜ í•™ìŠµì„ ì‹œì‘í•´ì„œ ì—°ì† í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”!")
        elif streak >= 7:
            insights.append(f"ğŸ”¥ {streak}ì¼ ì—°ì† í•™ìŠµ ì¤‘! ëŒ€ë‹¨í•´ìš”!")

        avg_score = stats.get("average_quiz_score", 0)
        if avg_score > 0:
            if avg_score < 60:
                insights.append("ğŸ“‰ í€´ì¦ˆ ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤. ë‹¨ì–´ ë³µìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.")
                recommendations.append("í€´ì¦ˆ ì „ì— ë‹¨ì–´ ì¹´ë“œë¥¼ ë³µìŠµí•˜ì„¸ìš”")
            elif avg_score >= 90:
                insights.append("ğŸ¯ í€´ì¦ˆ ì„±ì ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤!")

        return {
            "summary": {
                "total_words": total,
                "mastered_words": mastered,
                "avg_quiz_score": avg_score,
                "current_streak": streak,
            },
            "insights": insights or ["ì•„ì§ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•™ìŠµì„ ì‹œì‘í•´ë³´ì„¸ìš”!"],
            "recommendations": recommendations or ["ì˜¤ëŠ˜ ë‹¨ì–´ 10ê°œë¥¼ í•™ìŠµí•´ë³´ì„¸ìš”!"],
        }

    def predict_retention(self, word_list: List[str]) -> List[dict]:
        """
        ë‹¨ì–´ ê¸°ì–µ ìœ ì§€ìœ¨ ì˜ˆì¸¡ (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)

        Args:
            word_list: ë‹¨ì–´ ëª©ë¡

        Returns:
            ë‹¨ì–´ë³„ ìœ ì§€ìœ¨ ì˜ˆì¸¡
        """
        predictions = []
        for word in word_list:
            data = self.tracker.get_word_data(word)
            if not data:
                continue

            interval = data.get("interval", 0)
            repetitions = data.get("repetitions", 0)
            ef = data.get("easiness_factor", 2.5)

            # ë‹¨ìˆœ ì¶”ì •: ë°˜ë³µ íšŸìˆ˜ì™€ EF ê¸°ë°˜
            retention = min(0.95, 0.5 + (repetitions * 0.1) + (ef - 1.3) * 0.1)

            predictions.append({
                "word": word,
                "retention_probability": round(retention, 2),
                "days_since_review": interval,
                "recommended_action": "ë³µìŠµ í•„ìš”" if retention < 0.7 else "OK",
            })

        return predictions


class OrchestratorAgent:
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—ì´ì „íŠ¸ - ì‚¬ìš©ì ì˜ë„ íŒŒì•… ë° ì „ë¬¸ ì—ì´ì „íŠ¸ ì¡°ìœ¨"""

    def __init__(self, progress_tracker=None):
        self.content_agent = ContentAgent()
        self.tutor_agent = TutorAgent()
        self.eval_agent = EvalAgent()
        self.data_agent = DataAgent(progress_tracker) if progress_tracker else None

    def process_query(self, query: str, context: dict = None) -> dict:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ ë¶„ì„ ë° ì ì ˆí•œ ì—ì´ì „íŠ¸ì— ìœ„ì„

        Args:
            query: ì‚¬ìš©ì ì…ë ¥
            context: í˜„ì¬ í•™ìŠµ ì»¨í…ìŠ¤íŠ¸

        Returns:
            {"intent": str, "result": dict, "agent_used": str}
        """
        if context is None:
            context = {}

        intent = self._classify_intent(query)

        if intent == "learn":
            words = context.get("current_words", ["ä½ å¥½", "è°¢è°¢", "å†è§"])
            result = self.content_agent.generate_lesson(words)
            return {"intent": intent, "result": result, "agent_used": "ContentAgent"}

        elif intent == "practice":
            result = self.tutor_agent.chat(query, context.get("user_level", "beginner"))
            return {"intent": intent, "result": result, "agent_used": "TutorAgent"}

        elif intent == "quiz":
            words = context.get("vocabulary", [])
            scores = context.get("recent_scores", [])
            result = self.eval_agent.generate_adaptive_quiz(words, scores)
            return {"intent": intent, "result": result, "agent_used": "EvalAgent"}

        elif intent == "progress" and self.data_agent:
            result = self.data_agent.analyze_progress()
            return {"intent": intent, "result": result, "agent_used": "DataAgent"}

        else:
            result = self.tutor_agent.chat(query)
            return {"intent": "general", "result": result, "agent_used": "TutorAgent"}

    def _classify_intent(self, query: str) -> str:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ì˜ë„ ë¶„ë¥˜

        Returns:
            "learn", "practice", "quiz", "progress", "general"
        """
        query_lower = query.lower()

        learn_keywords = ["ë°°ìš°", "í•™ìŠµ", "ë‹¨ì–´", "lesson", "ë°°ìš¸", "learn"]
        practice_keywords = ["ì—°ìŠµ", "ëŒ€í™”", "practice", "chat", "ì–˜ê¸°", "ë§í•˜ê¸°"]
        quiz_keywords = ["í€´ì¦ˆ", "ì‹œí—˜", "quiz", "test", "ë¬¸ì œ", "ì±„ì "]
        progress_keywords = ["ì§„ë„", "í†µê³„", "progress", "stats", "ì„±ì ", "ì–¼ë§ˆë‚˜"]

        if any(k in query_lower for k in learn_keywords):
            return "learn"
        elif any(k in query_lower for k in practice_keywords):
            return "practice"
        elif any(k in query_lower for k in quiz_keywords):
            return "quiz"
        elif any(k in query_lower for k in progress_keywords):
            return "progress"
        return "general"
